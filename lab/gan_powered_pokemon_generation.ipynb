{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters taken from https://arxiv.org/pdf/1511.06434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "nz = 100                # Size of the latent z vector (input to the generator)\n",
    "ngf = 64                # Size of feature maps in the generator\n",
    "ndf = 64                # Size of feature maps in the discriminator\n",
    "nc = 3                  # Number of channels in the training images. For colored images this is 3\n",
    "lr = 0.0002             # Learning rate for optimizers\n",
    "betas = (0.5, 0.999)    # Beta1 and Beta2 hyperparameters for Adam optimizer\n",
    "batch_size = 128        # Batch size during training\n",
    "num_epochs = 50         # Number of training epochs\n",
    "weight_init_mean = 0.0\n",
    "weight_init_std = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure taken from https://arxiv.org/pdf/1511.06434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator implementation\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator implementation\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization function for the generator and discriminator\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, weight_init_mean, weight_init_std)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, weight_init_std)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(data_folder, output_folder, nz=100, ngf=64, ndf=64, nc=3, num_epochs=50, lr=0.0002, betas=(0.5, 0.999), batch_size=128):\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Image transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = datasets.ImageFolder(root=data_folder, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create the generator and discriminator\n",
    "    netG = Generator(nz=nz, ngf=ngf, nc=nc).to(device)\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "    netD = Discriminator(nc=nc, ndf=ndf).to(device)\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "    # Loss function and optimizers\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=betas)\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    # Noise for generating samples\n",
    "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "            # Update Discriminator with real data\n",
    "            netD.zero_grad()\n",
    "            real_images = data[0].to(device)\n",
    "            b_size = real_images.size(0)\n",
    "            label = torch.full((b_size,), 1., device=device)\n",
    "            output = netD(real_images).view(-1)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            # Update Discriminator with fake data\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            fake_images = netG(noise)\n",
    "            label.fill_(0.)\n",
    "            output = netD(fake_images.detach()).view(-1)\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "            # Update Generator\n",
    "            netG.zero_grad()\n",
    "            label.fill_(1.)\n",
    "            output = netD(fake_images).view(-1)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizerG.step()\n",
    "\n",
    "            # Print statistics\n",
    "            if i % 50 == 0:\n",
    "                print(f'Epoch [{epoch}/{num_epochs}] Batch {i}/{len(dataloader)} '\n",
    "                      f'Loss D: {errD.item():.4f}, Loss G: {errG.item():.4f}, '\n",
    "                      f'D(x): {D_x:.4f}, D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "\n",
    "        # Save images every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake_images = netG(fixed_noise).detach().cpu()\n",
    "            vutils.save_image(fake_images, f'{output_folder}/samples_epoch_{epoch}.png', normalize=True)\n",
    "\n",
    "    # Save final models\n",
    "    torch.save(netG.state_dict(), f'{output_folder}/models/generator.pth')\n",
    "    torch.save(netD.state_dict(), f'{output_folder}/models/discriminator.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D_x: Describes the average output of the Discriminator for real images\n",
    "###\n",
    "### D_G_z1: Describes the average output of the Discriminator for fake images before the Generator update\n",
    "###\n",
    "### D_G_z2: Describes the average output of the Discriminator for fake images after the Generator update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500] Batch 0/8 Loss D: 1.8052, Loss G: 1.9593, D(x): 0.2843, D(G(z)): 0.2644 / 0.1809\n",
      "Epoch [1/500] Batch 0/8 Loss D: 0.3008, Loss G: 6.4154, D(x): 0.8794, D(G(z)): 0.0602 / 0.0029\n",
      "Epoch [2/500] Batch 0/8 Loss D: 0.1789, Loss G: 5.8592, D(x): 0.8893, D(G(z)): 0.0366 / 0.0047\n",
      "Epoch [3/500] Batch 0/8 Loss D: 0.0299, Loss G: 4.4396, D(x): 0.9889, D(G(z)): 0.0145 / 0.0175\n",
      "Epoch [4/500] Batch 0/8 Loss D: 0.1812, Loss G: 9.2975, D(x): 0.8885, D(G(z)): 0.0002 / 0.0002\n",
      "Epoch [5/500] Batch 0/8 Loss D: 4.3191, Loss G: 22.5546, D(x): 0.0478, D(G(z)): 0.0000 / 0.0000\n",
      "Epoch [6/500] Batch 0/8 Loss D: 1.3619, Loss G: 18.2902, D(x): 0.9836, D(G(z)): 0.6345 / 0.0000\n",
      "Epoch [7/500] Batch 0/8 Loss D: 0.2262, Loss G: 10.8749, D(x): 0.8811, D(G(z)): 0.0000 / 0.0001\n",
      "Epoch [8/500] Batch 0/8 Loss D: 1.0400, Loss G: 15.5426, D(x): 0.9786, D(G(z)): 0.5488 / 0.0000\n",
      "Epoch [9/500] Batch 0/8 Loss D: 0.2173, Loss G: 5.0966, D(x): 0.8786, D(G(z)): 0.0328 / 0.0277\n",
      "Epoch [10/500] Batch 0/8 Loss D: 2.0145, Loss G: 12.7077, D(x): 0.9642, D(G(z)): 0.7834 / 0.0000\n",
      "Epoch [11/500] Batch 0/8 Loss D: 0.9980, Loss G: 8.1565, D(x): 0.9541, D(G(z)): 0.5391 / 0.0008\n",
      "Epoch [12/500] Batch 0/8 Loss D: 0.5466, Loss G: 4.2551, D(x): 0.6494, D(G(z)): 0.0145 / 0.0323\n",
      "Epoch [13/500] Batch 0/8 Loss D: 0.1668, Loss G: 5.2835, D(x): 0.8908, D(G(z)): 0.0348 / 0.0076\n",
      "Epoch [14/500] Batch 0/8 Loss D: 0.1173, Loss G: 6.8650, D(x): 0.9314, D(G(z)): 0.0392 / 0.0015\n",
      "Epoch [15/500] Batch 0/8 Loss D: 0.3495, Loss G: 6.9994, D(x): 0.8740, D(G(z)): 0.1586 / 0.0017\n",
      "Epoch [16/500] Batch 0/8 Loss D: 3.6774, Loss G: 14.7759, D(x): 0.9974, D(G(z)): 0.9624 / 0.0000\n",
      "Epoch [17/500] Batch 0/8 Loss D: 0.1320, Loss G: 4.3727, D(x): 0.9357, D(G(z)): 0.0524 / 0.0165\n",
      "Epoch [18/500] Batch 0/8 Loss D: 0.2263, Loss G: 4.4539, D(x): 0.9088, D(G(z)): 0.1031 / 0.0143\n",
      "Epoch [19/500] Batch 0/8 Loss D: 0.2241, Loss G: 5.2060, D(x): 0.9476, D(G(z)): 0.1471 / 0.0068\n",
      "Epoch [20/500] Batch 0/8 Loss D: 8.1434, Loss G: 7.3517, D(x): 0.9999, D(G(z)): 0.9908 / 0.0356\n",
      "Epoch [21/500] Batch 0/8 Loss D: 0.1733, Loss G: 3.4276, D(x): 0.9389, D(G(z)): 0.0927 / 0.0443\n",
      "Epoch [22/500] Batch 0/8 Loss D: 0.2616, Loss G: 4.7178, D(x): 0.9886, D(G(z)): 0.2129 / 0.0107\n",
      "Epoch [23/500] Batch 0/8 Loss D: 0.7389, Loss G: 11.4111, D(x): 0.9960, D(G(z)): 0.4565 / 0.0000\n",
      "Epoch [24/500] Batch 0/8 Loss D: 0.0436, Loss G: 5.6524, D(x): 0.9805, D(G(z)): 0.0231 / 0.0049\n",
      "Epoch [25/500] Batch 0/8 Loss D: 0.1706, Loss G: 8.4404, D(x): 0.9291, D(G(z)): 0.0682 / 0.0011\n",
      "Epoch [26/500] Batch 0/8 Loss D: 1.7627, Loss G: 13.2536, D(x): 0.9792, D(G(z)): 0.7727 / 0.0000\n",
      "Epoch [27/500] Batch 0/8 Loss D: 0.2245, Loss G: 4.8681, D(x): 0.9572, D(G(z)): 0.1514 / 0.0107\n",
      "Epoch [28/500] Batch 0/8 Loss D: 0.3168, Loss G: 4.6726, D(x): 0.9392, D(G(z)): 0.2130 / 0.0122\n",
      "Epoch [29/500] Batch 0/8 Loss D: 1.2189, Loss G: 10.8915, D(x): 0.9837, D(G(z)): 0.6589 / 0.0000\n",
      "Epoch [30/500] Batch 0/8 Loss D: 1.2991, Loss G: 10.6204, D(x): 0.9674, D(G(z)): 0.6720 / 0.0000\n",
      "Epoch [31/500] Batch 0/8 Loss D: 0.5491, Loss G: 3.4416, D(x): 0.8122, D(G(z)): 0.2324 / 0.0556\n",
      "Epoch [32/500] Batch 0/8 Loss D: 1.8185, Loss G: 6.2988, D(x): 0.9877, D(G(z)): 0.7628 / 0.0050\n",
      "Epoch [33/500] Batch 0/8 Loss D: 1.2291, Loss G: 6.6748, D(x): 0.9132, D(G(z)): 0.6080 / 0.0024\n",
      "Epoch [34/500] Batch 0/8 Loss D: 0.6245, Loss G: 2.1711, D(x): 0.6391, D(G(z)): 0.0887 / 0.1410\n",
      "Epoch [35/500] Batch 0/8 Loss D: 2.0570, Loss G: 6.8738, D(x): 0.9916, D(G(z)): 0.7973 / 0.0019\n",
      "Epoch [36/500] Batch 0/8 Loss D: 1.3630, Loss G: 6.6910, D(x): 0.9840, D(G(z)): 0.6907 / 0.0026\n",
      "Epoch [37/500] Batch 0/8 Loss D: 1.4526, Loss G: 1.5433, D(x): 0.2969, D(G(z)): 0.0044 / 0.2686\n",
      "Epoch [38/500] Batch 0/8 Loss D: 0.6855, Loss G: 6.3609, D(x): 0.9691, D(G(z)): 0.4509 / 0.0031\n",
      "Epoch [39/500] Batch 0/8 Loss D: 0.5771, Loss G: 5.2522, D(x): 0.8870, D(G(z)): 0.3297 / 0.0076\n",
      "Epoch [40/500] Batch 0/8 Loss D: 0.5346, Loss G: 4.8156, D(x): 0.9751, D(G(z)): 0.3646 / 0.0122\n",
      "Epoch [41/500] Batch 0/8 Loss D: 3.6715, Loss G: 3.4204, D(x): 0.0571, D(G(z)): 0.0006 / 0.0928\n",
      "Epoch [42/500] Batch 0/8 Loss D: 0.3081, Loss G: 3.5750, D(x): 0.8771, D(G(z)): 0.1321 / 0.0374\n",
      "Epoch [43/500] Batch 0/8 Loss D: 2.1794, Loss G: 3.0632, D(x): 0.2310, D(G(z)): 0.0244 / 0.1183\n",
      "Epoch [44/500] Batch 0/8 Loss D: 0.8261, Loss G: 5.5947, D(x): 0.9067, D(G(z)): 0.4753 / 0.0062\n",
      "Epoch [45/500] Batch 0/8 Loss D: 0.2184, Loss G: 3.8151, D(x): 0.8942, D(G(z)): 0.0911 / 0.0305\n",
      "Epoch [46/500] Batch 0/8 Loss D: 0.3162, Loss G: 3.9304, D(x): 0.8471, D(G(z)): 0.1137 / 0.0538\n",
      "Epoch [47/500] Batch 0/8 Loss D: 0.6292, Loss G: 6.4348, D(x): 0.9626, D(G(z)): 0.4106 / 0.0028\n",
      "Epoch [48/500] Batch 0/8 Loss D: 2.7144, Loss G: 8.9453, D(x): 0.9942, D(G(z)): 0.9008 / 0.0003\n",
      "Epoch [49/500] Batch 0/8 Loss D: 0.5261, Loss G: 4.8334, D(x): 0.9129, D(G(z)): 0.3203 / 0.0124\n",
      "Epoch [50/500] Batch 0/8 Loss D: 0.5523, Loss G: 5.1847, D(x): 0.9199, D(G(z)): 0.3488 / 0.0089\n",
      "Epoch [51/500] Batch 0/8 Loss D: 1.0442, Loss G: 8.2882, D(x): 0.9551, D(G(z)): 0.5697 / 0.0005\n",
      "Epoch [52/500] Batch 0/8 Loss D: 0.4993, Loss G: 3.1136, D(x): 0.8189, D(G(z)): 0.2017 / 0.0681\n",
      "Epoch [53/500] Batch 0/8 Loss D: 0.4352, Loss G: 1.8917, D(x): 0.7236, D(G(z)): 0.0698 / 0.1825\n",
      "Epoch [54/500] Batch 0/8 Loss D: 0.8269, Loss G: 1.2767, D(x): 0.5111, D(G(z)): 0.0206 / 0.3864\n",
      "Epoch [55/500] Batch 0/8 Loss D: 1.6331, Loss G: 6.7696, D(x): 0.9893, D(G(z)): 0.7267 / 0.0025\n",
      "Epoch [56/500] Batch 0/8 Loss D: 0.9482, Loss G: 6.2601, D(x): 0.8883, D(G(z)): 0.5022 / 0.0045\n",
      "Epoch [57/500] Batch 0/8 Loss D: 0.5008, Loss G: 4.2961, D(x): 0.8232, D(G(z)): 0.2020 / 0.0225\n",
      "Epoch [58/500] Batch 0/8 Loss D: 0.3869, Loss G: 2.4074, D(x): 0.7359, D(G(z)): 0.0309 / 0.1205\n",
      "Epoch [59/500] Batch 0/8 Loss D: 1.0729, Loss G: 9.6438, D(x): 0.9836, D(G(z)): 0.6055 / 0.0001\n",
      "Epoch [60/500] Batch 0/8 Loss D: 0.7660, Loss G: 3.2381, D(x): 0.5420, D(G(z)): 0.0209 / 0.1033\n",
      "Epoch [61/500] Batch 0/8 Loss D: 0.9665, Loss G: 1.7780, D(x): 0.4494, D(G(z)): 0.0169 / 0.2349\n",
      "Epoch [62/500] Batch 0/8 Loss D: 0.8235, Loss G: 0.8306, D(x): 0.5050, D(G(z)): 0.0319 / 0.4941\n",
      "Epoch [63/500] Batch 0/8 Loss D: 0.5900, Loss G: 2.4568, D(x): 0.6270, D(G(z)): 0.0487 / 0.1192\n",
      "Epoch [64/500] Batch 0/8 Loss D: 0.6517, Loss G: 1.6951, D(x): 0.5787, D(G(z)): 0.0380 / 0.2512\n",
      "Epoch [65/500] Batch 0/8 Loss D: 0.3522, Loss G: 3.7392, D(x): 0.8249, D(G(z)): 0.1269 / 0.0347\n",
      "Epoch [66/500] Batch 0/8 Loss D: 0.6641, Loss G: 8.4808, D(x): 0.9527, D(G(z)): 0.4240 / 0.0004\n",
      "Epoch [67/500] Batch 0/8 Loss D: 2.1372, Loss G: 2.7006, D(x): 0.2025, D(G(z)): 0.0071 / 0.1583\n",
      "Epoch [68/500] Batch 0/8 Loss D: 0.4038, Loss G: 4.1874, D(x): 0.7237, D(G(z)): 0.0429 / 0.0288\n",
      "Epoch [69/500] Batch 0/8 Loss D: 0.5165, Loss G: 4.6859, D(x): 0.9495, D(G(z)): 0.3308 / 0.0158\n",
      "Epoch [70/500] Batch 0/8 Loss D: 1.0715, Loss G: 7.3060, D(x): 0.9814, D(G(z)): 0.6037 / 0.0017\n",
      "Epoch [71/500] Batch 0/8 Loss D: 0.7326, Loss G: 6.0049, D(x): 0.9474, D(G(z)): 0.4539 / 0.0044\n",
      "Epoch [72/500] Batch 0/8 Loss D: 0.2966, Loss G: 4.6412, D(x): 0.9165, D(G(z)): 0.1506 / 0.0158\n",
      "Epoch [73/500] Batch 0/8 Loss D: 0.3835, Loss G: 3.9668, D(x): 0.8662, D(G(z)): 0.1973 / 0.0287\n",
      "Epoch [74/500] Batch 0/8 Loss D: 0.9633, Loss G: 9.2223, D(x): 0.9763, D(G(z)): 0.5044 / 0.0003\n",
      "Epoch [75/500] Batch 0/8 Loss D: 0.4859, Loss G: 6.3826, D(x): 0.9714, D(G(z)): 0.3361 / 0.0035\n",
      "Epoch [76/500] Batch 0/8 Loss D: 0.5196, Loss G: 4.2679, D(x): 0.8333, D(G(z)): 0.2554 / 0.0229\n",
      "Epoch [77/500] Batch 0/8 Loss D: 0.3819, Loss G: 5.6892, D(x): 0.9299, D(G(z)): 0.2502 / 0.0050\n",
      "Epoch [78/500] Batch 0/8 Loss D: 0.4269, Loss G: 2.6363, D(x): 0.7134, D(G(z)): 0.0500 / 0.1082\n",
      "Epoch [79/500] Batch 0/8 Loss D: 0.3086, Loss G: 2.5905, D(x): 0.8137, D(G(z)): 0.0811 / 0.0978\n",
      "Epoch [80/500] Batch 0/8 Loss D: 1.7364, Loss G: 9.8177, D(x): 0.9954, D(G(z)): 0.7534 / 0.0002\n",
      "Epoch [81/500] Batch 0/8 Loss D: 1.8200, Loss G: 5.4077, D(x): 0.9939, D(G(z)): 0.7652 / 0.0100\n",
      "Epoch [82/500] Batch 0/8 Loss D: 1.4459, Loss G: 8.1237, D(x): 0.9861, D(G(z)): 0.6775 / 0.0008\n",
      "Epoch [83/500] Batch 0/8 Loss D: 0.3381, Loss G: 4.0340, D(x): 0.8785, D(G(z)): 0.1667 / 0.0255\n",
      "Epoch [84/500] Batch 0/8 Loss D: 0.4886, Loss G: 4.9990, D(x): 0.9316, D(G(z)): 0.3212 / 0.0126\n",
      "Epoch [85/500] Batch 0/8 Loss D: 0.7598, Loss G: 2.1762, D(x): 0.5141, D(G(z)): 0.0116 / 0.1729\n",
      "Epoch [86/500] Batch 0/8 Loss D: 0.3752, Loss G: 4.0848, D(x): 0.8500, D(G(z)): 0.1751 / 0.0246\n",
      "Epoch [87/500] Batch 0/8 Loss D: 0.3929, Loss G: 3.8551, D(x): 0.8418, D(G(z)): 0.1741 / 0.0299\n",
      "Epoch [88/500] Batch 0/8 Loss D: 0.2386, Loss G: 3.2644, D(x): 0.8820, D(G(z)): 0.0930 / 0.0626\n",
      "Epoch [89/500] Batch 0/8 Loss D: 1.1023, Loss G: 8.8875, D(x): 0.9838, D(G(z)): 0.6271 / 0.0004\n",
      "Epoch [90/500] Batch 0/8 Loss D: 1.0358, Loss G: 3.9515, D(x): 0.4293, D(G(z)): 0.0022 / 0.0344\n",
      "Epoch [91/500] Batch 0/8 Loss D: 0.4681, Loss G: 3.5951, D(x): 0.7344, D(G(z)): 0.0884 / 0.0547\n",
      "Epoch [92/500] Batch 0/8 Loss D: 1.4300, Loss G: 9.2366, D(x): 0.9856, D(G(z)): 0.6957 / 0.0003\n",
      "Epoch [93/500] Batch 0/8 Loss D: 1.2190, Loss G: 8.1868, D(x): 0.9912, D(G(z)): 0.6333 / 0.0009\n",
      "Epoch [94/500] Batch 0/8 Loss D: 2.0651, Loss G: 9.3794, D(x): 0.9877, D(G(z)): 0.8201 / 0.0003\n",
      "Epoch [95/500] Batch 0/8 Loss D: 0.4441, Loss G: 2.7143, D(x): 0.7325, D(G(z)): 0.0722 / 0.0979\n",
      "Epoch [96/500] Batch 0/8 Loss D: 0.3542, Loss G: 4.9646, D(x): 0.9237, D(G(z)): 0.2220 / 0.0114\n",
      "Epoch [97/500] Batch 0/8 Loss D: 0.2496, Loss G: 3.5132, D(x): 0.8981, D(G(z)): 0.1225 / 0.0412\n",
      "Epoch [98/500] Batch 0/8 Loss D: 1.0434, Loss G: 8.9596, D(x): 0.9731, D(G(z)): 0.5874 / 0.0003\n",
      "Epoch [99/500] Batch 0/8 Loss D: 0.6760, Loss G: 6.1415, D(x): 0.9579, D(G(z)): 0.4228 / 0.0050\n",
      "Epoch [100/500] Batch 0/8 Loss D: 2.0514, Loss G: 8.5819, D(x): 0.9921, D(G(z)): 0.7876 / 0.0018\n",
      "Epoch [101/500] Batch 0/8 Loss D: 0.4157, Loss G: 3.7014, D(x): 0.8242, D(G(z)): 0.1645 / 0.0405\n",
      "Epoch [102/500] Batch 0/8 Loss D: 0.6084, Loss G: 2.5242, D(x): 0.6311, D(G(z)): 0.0407 / 0.1463\n",
      "Epoch [103/500] Batch 0/8 Loss D: 0.3597, Loss G: 2.9626, D(x): 0.8178, D(G(z)): 0.1291 / 0.0696\n",
      "Epoch [104/500] Batch 0/8 Loss D: 0.8591, Loss G: 7.0632, D(x): 0.9499, D(G(z)): 0.4956 / 0.0018\n",
      "Epoch [105/500] Batch 0/8 Loss D: 0.5317, Loss G: 5.0308, D(x): 0.9584, D(G(z)): 0.3416 / 0.0139\n",
      "Epoch [106/500] Batch 0/8 Loss D: 0.3408, Loss G: 4.5035, D(x): 0.9101, D(G(z)): 0.2002 / 0.0180\n",
      "Epoch [107/500] Batch 0/8 Loss D: 1.7076, Loss G: 9.5906, D(x): 0.9884, D(G(z)): 0.7780 / 0.0002\n",
      "Epoch [108/500] Batch 0/8 Loss D: 1.2865, Loss G: 6.7795, D(x): 0.9807, D(G(z)): 0.6543 / 0.0032\n",
      "Epoch [109/500] Batch 0/8 Loss D: 1.4544, Loss G: 6.7930, D(x): 0.9857, D(G(z)): 0.6943 / 0.0044\n",
      "Epoch [110/500] Batch 0/8 Loss D: 0.6594, Loss G: 5.8025, D(x): 0.9287, D(G(z)): 0.4009 / 0.0048\n",
      "Epoch [111/500] Batch 0/8 Loss D: 0.3737, Loss G: 4.7346, D(x): 0.9500, D(G(z)): 0.2456 / 0.0206\n",
      "Epoch [112/500] Batch 0/8 Loss D: 0.3875, Loss G: 4.2063, D(x): 0.9650, D(G(z)): 0.2706 / 0.0245\n",
      "Epoch [113/500] Batch 0/8 Loss D: 1.1378, Loss G: 6.9037, D(x): 0.9827, D(G(z)): 0.5951 / 0.0023\n",
      "Epoch [114/500] Batch 0/8 Loss D: 0.8830, Loss G: 6.7768, D(x): 0.9458, D(G(z)): 0.4718 / 0.0029\n",
      "Epoch [115/500] Batch 0/8 Loss D: 0.2962, Loss G: 5.5084, D(x): 0.9447, D(G(z)): 0.1848 / 0.0077\n",
      "Epoch [116/500] Batch 0/8 Loss D: 1.9209, Loss G: 8.0388, D(x): 0.9913, D(G(z)): 0.7965 / 0.0009\n",
      "Epoch [117/500] Batch 0/8 Loss D: 0.5052, Loss G: 2.2420, D(x): 0.7166, D(G(z)): 0.0992 / 0.1579\n",
      "Epoch [118/500] Batch 0/8 Loss D: 0.3382, Loss G: 4.5773, D(x): 0.9163, D(G(z)): 0.2038 / 0.0181\n",
      "Epoch [119/500] Batch 0/8 Loss D: 0.4243, Loss G: 4.1372, D(x): 0.9363, D(G(z)): 0.2711 / 0.0263\n",
      "Epoch [120/500] Batch 0/8 Loss D: 0.3636, Loss G: 4.2532, D(x): 0.9091, D(G(z)): 0.2084 / 0.0219\n",
      "Epoch [121/500] Batch 0/8 Loss D: 0.7951, Loss G: 6.7314, D(x): 0.9648, D(G(z)): 0.4773 / 0.0023\n",
      "Epoch [122/500] Batch 0/8 Loss D: 1.3094, Loss G: 7.3985, D(x): 0.9877, D(G(z)): 0.6648 / 0.0016\n",
      "Epoch [123/500] Batch 0/8 Loss D: 0.8023, Loss G: 5.7270, D(x): 0.9472, D(G(z)): 0.4690 / 0.0056\n",
      "Epoch [124/500] Batch 0/8 Loss D: 0.7185, Loss G: 6.0228, D(x): 0.9141, D(G(z)): 0.4281 / 0.0044\n",
      "Epoch [125/500] Batch 0/8 Loss D: 0.4336, Loss G: 2.5393, D(x): 0.7417, D(G(z)): 0.0819 / 0.1223\n",
      "Epoch [126/500] Batch 0/8 Loss D: 0.2443, Loss G: 4.3713, D(x): 0.8943, D(G(z)): 0.1111 / 0.0228\n",
      "Epoch [127/500] Batch 0/8 Loss D: 0.2737, Loss G: 3.1181, D(x): 0.8162, D(G(z)): 0.0497 / 0.0702\n",
      "Epoch [128/500] Batch 0/8 Loss D: 2.7278, Loss G: 6.3368, D(x): 0.9974, D(G(z)): 0.9029 / 0.0059\n",
      "Epoch [129/500] Batch 0/8 Loss D: 1.6539, Loss G: 6.7452, D(x): 0.9526, D(G(z)): 0.7351 / 0.0025\n",
      "Epoch [130/500] Batch 0/8 Loss D: 1.2850, Loss G: 7.8107, D(x): 0.9517, D(G(z)): 0.6085 / 0.0009\n",
      "Epoch [131/500] Batch 0/8 Loss D: 0.3729, Loss G: 2.9392, D(x): 0.8116, D(G(z)): 0.1221 / 0.0725\n",
      "Epoch [132/500] Batch 0/8 Loss D: 0.4443, Loss G: 4.2276, D(x): 0.9441, D(G(z)): 0.2968 / 0.0226\n",
      "Epoch [133/500] Batch 0/8 Loss D: 0.6212, Loss G: 5.0793, D(x): 0.9511, D(G(z)): 0.3864 / 0.0102\n",
      "Epoch [134/500] Batch 0/8 Loss D: 0.4481, Loss G: 2.0140, D(x): 0.7409, D(G(z)): 0.1093 / 0.1662\n",
      "Epoch [135/500] Batch 0/8 Loss D: 0.6742, Loss G: 5.4312, D(x): 0.9455, D(G(z)): 0.4201 / 0.0076\n",
      "Epoch [136/500] Batch 0/8 Loss D: 0.3271, Loss G: 3.8178, D(x): 0.9210, D(G(z)): 0.1980 / 0.0356\n",
      "Epoch [137/500] Batch 0/8 Loss D: 0.3558, Loss G: 3.1613, D(x): 0.7900, D(G(z)): 0.0888 / 0.0953\n",
      "Epoch [138/500] Batch 0/8 Loss D: 0.4411, Loss G: 5.9031, D(x): 0.9627, D(G(z)): 0.3025 / 0.0050\n",
      "Epoch [139/500] Batch 0/8 Loss D: 0.3331, Loss G: 2.7543, D(x): 0.8262, D(G(z)): 0.1093 / 0.0920\n",
      "Epoch [140/500] Batch 0/8 Loss D: 0.4208, Loss G: 4.4502, D(x): 0.9452, D(G(z)): 0.2693 / 0.0210\n",
      "Epoch [141/500] Batch 0/8 Loss D: 0.3786, Loss G: 2.8729, D(x): 0.7851, D(G(z)): 0.1051 / 0.0870\n",
      "Epoch [142/500] Batch 0/8 Loss D: 0.5704, Loss G: 6.0318, D(x): 0.9686, D(G(z)): 0.3806 / 0.0041\n",
      "Epoch [143/500] Batch 0/8 Loss D: 0.4645, Loss G: 4.6604, D(x): 0.9681, D(G(z)): 0.3234 / 0.0141\n",
      "Epoch [144/500] Batch 0/8 Loss D: 0.5321, Loss G: 5.3867, D(x): 0.9826, D(G(z)): 0.3599 / 0.0077\n",
      "Epoch [145/500] Batch 0/8 Loss D: 0.2743, Loss G: 4.1015, D(x): 0.9398, D(G(z)): 0.1720 / 0.0276\n",
      "Epoch [146/500] Batch 0/8 Loss D: 0.3152, Loss G: 2.7160, D(x): 0.8199, D(G(z)): 0.0946 / 0.0966\n",
      "Epoch [147/500] Batch 0/8 Loss D: 0.5303, Loss G: 5.7715, D(x): 0.9625, D(G(z)): 0.3291 / 0.0055\n",
      "Epoch [148/500] Batch 0/8 Loss D: 1.0058, Loss G: 1.5075, D(x): 0.4634, D(G(z)): 0.0351 / 0.3893\n",
      "Epoch [149/500] Batch 0/8 Loss D: 0.5929, Loss G: 6.3302, D(x): 0.9230, D(G(z)): 0.3469 / 0.0036\n",
      "Epoch [150/500] Batch 0/8 Loss D: 0.4231, Loss G: 3.6189, D(x): 0.8141, D(G(z)): 0.1617 / 0.0434\n",
      "Epoch [151/500] Batch 0/8 Loss D: 1.0650, Loss G: 6.8009, D(x): 0.9862, D(G(z)): 0.5813 / 0.0022\n",
      "Epoch [152/500] Batch 0/8 Loss D: 0.3282, Loss G: 3.2215, D(x): 0.7968, D(G(z)): 0.0687 / 0.0728\n",
      "Epoch [153/500] Batch 0/8 Loss D: 0.5726, Loss G: 4.5061, D(x): 0.9819, D(G(z)): 0.3738 / 0.0167\n",
      "Epoch [154/500] Batch 0/8 Loss D: 0.4644, Loss G: 4.2198, D(x): 0.9504, D(G(z)): 0.3077 / 0.0228\n",
      "Epoch [155/500] Batch 0/8 Loss D: 0.8956, Loss G: 5.9319, D(x): 0.9895, D(G(z)): 0.5067 / 0.0060\n",
      "Epoch [156/500] Batch 0/8 Loss D: 0.4825, Loss G: 4.0139, D(x): 0.8677, D(G(z)): 0.2379 / 0.0407\n",
      "Epoch [157/500] Batch 0/8 Loss D: 1.0792, Loss G: 8.3935, D(x): 0.9866, D(G(z)): 0.5836 / 0.0005\n",
      "Epoch [158/500] Batch 0/8 Loss D: 0.3444, Loss G: 3.7201, D(x): 0.7719, D(G(z)): 0.0469 / 0.0655\n",
      "Epoch [159/500] Batch 0/8 Loss D: 0.5447, Loss G: 5.0183, D(x): 0.8846, D(G(z)): 0.2839 / 0.0140\n",
      "Epoch [160/500] Batch 0/8 Loss D: 1.5955, Loss G: 6.6653, D(x): 0.9940, D(G(z)): 0.6938 / 0.0043\n",
      "Epoch [161/500] Batch 0/8 Loss D: 0.5919, Loss G: 5.6482, D(x): 0.9332, D(G(z)): 0.3538 / 0.0083\n",
      "Epoch [162/500] Batch 0/8 Loss D: 0.7253, Loss G: 5.4832, D(x): 0.9720, D(G(z)): 0.4325 / 0.0088\n",
      "Epoch [163/500] Batch 0/8 Loss D: 0.3607, Loss G: 2.6785, D(x): 0.7966, D(G(z)): 0.1007 / 0.1001\n",
      "Epoch [164/500] Batch 0/8 Loss D: 0.3331, Loss G: 4.4197, D(x): 0.9596, D(G(z)): 0.2292 / 0.0185\n",
      "Epoch [165/500] Batch 0/8 Loss D: 0.3238, Loss G: 4.0732, D(x): 0.9201, D(G(z)): 0.1962 / 0.0260\n",
      "Epoch [166/500] Batch 0/8 Loss D: 0.2070, Loss G: 3.7277, D(x): 0.8545, D(G(z)): 0.0375 / 0.0431\n",
      "Epoch [167/500] Batch 0/8 Loss D: 0.3040, Loss G: 3.0053, D(x): 0.8407, D(G(z)): 0.1043 / 0.0784\n",
      "Epoch [168/500] Batch 0/8 Loss D: 1.1288, Loss G: 7.2092, D(x): 0.9890, D(G(z)): 0.5996 / 0.0018\n",
      "Epoch [169/500] Batch 0/8 Loss D: 0.5477, Loss G: 5.5964, D(x): 0.9682, D(G(z)): 0.3384 / 0.0090\n",
      "Epoch [170/500] Batch 0/8 Loss D: 0.3526, Loss G: 3.0996, D(x): 0.7756, D(G(z)): 0.0619 / 0.0834\n",
      "Epoch [171/500] Batch 0/8 Loss D: 0.2723, Loss G: 3.5119, D(x): 0.8794, D(G(z)): 0.1190 / 0.0476\n",
      "Epoch [172/500] Batch 0/8 Loss D: 0.2802, Loss G: 3.7893, D(x): 0.9106, D(G(z)): 0.1559 / 0.0371\n",
      "Epoch [173/500] Batch 0/8 Loss D: 0.4321, Loss G: 4.9193, D(x): 0.9592, D(G(z)): 0.2870 / 0.0128\n",
      "Epoch [174/500] Batch 0/8 Loss D: 0.3333, Loss G: 5.2840, D(x): 0.9619, D(G(z)): 0.2212 / 0.0094\n",
      "Epoch [175/500] Batch 0/8 Loss D: 0.7118, Loss G: 2.0802, D(x): 0.5539, D(G(z)): 0.0122 / 0.2222\n",
      "Epoch [176/500] Batch 0/8 Loss D: 1.3194, Loss G: 7.2545, D(x): 0.9904, D(G(z)): 0.6320 / 0.0024\n",
      "Epoch [177/500] Batch 0/8 Loss D: 0.5158, Loss G: 5.1529, D(x): 0.9787, D(G(z)): 0.3352 / 0.0128\n",
      "Epoch [178/500] Batch 0/8 Loss D: 0.5430, Loss G: 5.4122, D(x): 0.9694, D(G(z)): 0.3277 / 0.0114\n",
      "Epoch [179/500] Batch 0/8 Loss D: 0.3563, Loss G: 2.7248, D(x): 0.8015, D(G(z)): 0.1016 / 0.1148\n",
      "Epoch [180/500] Batch 0/8 Loss D: 0.1743, Loss G: 3.8771, D(x): 0.9332, D(G(z)): 0.0917 / 0.0355\n",
      "Epoch [181/500] Batch 0/8 Loss D: 0.3302, Loss G: 4.6350, D(x): 0.9451, D(G(z)): 0.2134 / 0.0155\n",
      "Epoch [182/500] Batch 0/8 Loss D: 0.2535, Loss G: 4.1112, D(x): 0.9499, D(G(z)): 0.1660 / 0.0270\n",
      "Epoch [183/500] Batch 0/8 Loss D: 0.4097, Loss G: 5.7499, D(x): 0.9685, D(G(z)): 0.2828 / 0.0054\n",
      "Epoch [184/500] Batch 0/8 Loss D: 0.6457, Loss G: 6.3923, D(x): 0.9797, D(G(z)): 0.3957 / 0.0035\n",
      "Epoch [185/500] Batch 0/8 Loss D: 0.4453, Loss G: 5.2096, D(x): 0.9563, D(G(z)): 0.2931 / 0.0098\n",
      "Epoch [186/500] Batch 0/8 Loss D: 1.3106, Loss G: 8.7938, D(x): 0.9918, D(G(z)): 0.6367 / 0.0005\n",
      "Epoch [187/500] Batch 0/8 Loss D: 0.4325, Loss G: 4.9123, D(x): 0.9351, D(G(z)): 0.2657 / 0.0123\n",
      "Epoch [188/500] Batch 0/8 Loss D: 0.8203, Loss G: 7.1189, D(x): 0.9744, D(G(z)): 0.4866 / 0.0018\n",
      "Epoch [189/500] Batch 0/8 Loss D: 0.5733, Loss G: 5.4473, D(x): 0.9858, D(G(z)): 0.3752 / 0.0077\n",
      "Epoch [190/500] Batch 0/8 Loss D: 0.2752, Loss G: 3.5312, D(x): 0.8917, D(G(z)): 0.1306 / 0.0495\n",
      "Epoch [191/500] Batch 0/8 Loss D: 0.1710, Loss G: 4.0152, D(x): 0.8971, D(G(z)): 0.0535 / 0.0351\n",
      "Epoch [192/500] Batch 0/8 Loss D: 0.2433, Loss G: 4.2539, D(x): 0.9567, D(G(z)): 0.1568 / 0.0280\n",
      "Epoch [193/500] Batch 0/8 Loss D: 0.2293, Loss G: 4.4388, D(x): 0.9501, D(G(z)): 0.1507 / 0.0195\n",
      "Epoch [194/500] Batch 0/8 Loss D: 0.7746, Loss G: 1.5158, D(x): 0.5168, D(G(z)): 0.0070 / 0.3113\n",
      "Epoch [195/500] Batch 0/8 Loss D: 0.4083, Loss G: 5.2016, D(x): 0.9715, D(G(z)): 0.2789 / 0.0096\n",
      "Epoch [196/500] Batch 0/8 Loss D: 0.2128, Loss G: 5.1114, D(x): 0.9719, D(G(z)): 0.1569 / 0.0099\n",
      "Epoch [197/500] Batch 0/8 Loss D: 1.4975, Loss G: 10.2824, D(x): 0.9941, D(G(z)): 0.6941 / 0.0002\n",
      "Epoch [198/500] Batch 0/8 Loss D: 0.5253, Loss G: 3.9262, D(x): 0.7329, D(G(z)): 0.1204 / 0.0607\n",
      "Epoch [199/500] Batch 0/8 Loss D: 2.0930, Loss G: 3.1097, D(x): 0.2428, D(G(z)): 0.0064 / 0.1886\n",
      "Epoch [200/500] Batch 0/8 Loss D: 0.4722, Loss G: 4.9978, D(x): 0.9292, D(G(z)): 0.2794 / 0.0146\n",
      "Epoch [201/500] Batch 0/8 Loss D: 0.2841, Loss G: 3.2359, D(x): 0.8211, D(G(z)): 0.0650 / 0.0680\n",
      "Epoch [202/500] Batch 0/8 Loss D: 0.7363, Loss G: 6.1623, D(x): 0.9779, D(G(z)): 0.4379 / 0.0045\n",
      "Epoch [203/500] Batch 0/8 Loss D: 0.3232, Loss G: 2.9529, D(x): 0.7977, D(G(z)): 0.0671 / 0.0961\n",
      "Epoch [204/500] Batch 0/8 Loss D: 0.4363, Loss G: 4.9253, D(x): 0.9869, D(G(z)): 0.3060 / 0.0134\n",
      "Epoch [205/500] Batch 0/8 Loss D: 0.5157, Loss G: 5.4362, D(x): 0.9757, D(G(z)): 0.3366 / 0.0087\n",
      "Epoch [206/500] Batch 0/8 Loss D: 0.4487, Loss G: 4.8444, D(x): 0.9719, D(G(z)): 0.2969 / 0.0136\n",
      "Epoch [207/500] Batch 0/8 Loss D: 0.1981, Loss G: 4.1462, D(x): 0.9283, D(G(z)): 0.1071 / 0.0387\n",
      "Epoch [208/500] Batch 0/8 Loss D: 0.5240, Loss G: 5.6364, D(x): 0.9740, D(G(z)): 0.3156 / 0.0091\n",
      "Epoch [209/500] Batch 0/8 Loss D: 0.3347, Loss G: 3.5107, D(x): 0.8426, D(G(z)): 0.1264 / 0.0576\n",
      "Epoch [210/500] Batch 0/8 Loss D: 0.5049, Loss G: 5.4409, D(x): 0.9779, D(G(z)): 0.3403 / 0.0083\n",
      "Epoch [211/500] Batch 0/8 Loss D: 0.3897, Loss G: 5.3336, D(x): 0.9649, D(G(z)): 0.2599 / 0.0077\n",
      "Epoch [212/500] Batch 0/8 Loss D: 0.2293, Loss G: 4.0894, D(x): 0.9441, D(G(z)): 0.1387 / 0.0293\n",
      "Epoch [213/500] Batch 0/8 Loss D: 1.4880, Loss G: 8.9241, D(x): 0.9951, D(G(z)): 0.6724 / 0.0004\n",
      "Epoch [214/500] Batch 0/8 Loss D: 0.4610, Loss G: 1.8228, D(x): 0.7236, D(G(z)): 0.0681 / 0.2457\n",
      "Epoch [215/500] Batch 0/8 Loss D: 0.3778, Loss G: 5.3921, D(x): 0.9458, D(G(z)): 0.2378 / 0.0124\n",
      "Epoch [216/500] Batch 0/8 Loss D: 0.2318, Loss G: 3.7924, D(x): 0.9460, D(G(z)): 0.1449 / 0.0397\n",
      "Epoch [217/500] Batch 0/8 Loss D: 0.2143, Loss G: 3.8080, D(x): 0.9329, D(G(z)): 0.1162 / 0.0422\n",
      "Epoch [218/500] Batch 0/8 Loss D: 0.2729, Loss G: 4.1457, D(x): 0.9599, D(G(z)): 0.1849 / 0.0283\n",
      "Epoch [219/500] Batch 0/8 Loss D: 0.2314, Loss G: 3.5638, D(x): 0.8264, D(G(z)): 0.0265 / 0.0503\n",
      "Epoch [220/500] Batch 0/8 Loss D: 0.4294, Loss G: 4.9255, D(x): 0.9802, D(G(z)): 0.2934 / 0.0148\n",
      "Epoch [221/500] Batch 0/8 Loss D: 0.1804, Loss G: 4.1175, D(x): 0.9667, D(G(z)): 0.1241 / 0.0285\n",
      "Epoch [222/500] Batch 0/8 Loss D: 0.7045, Loss G: 6.3522, D(x): 0.9927, D(G(z)): 0.4360 / 0.0035\n",
      "Epoch [223/500] Batch 0/8 Loss D: 0.1560, Loss G: 3.8558, D(x): 0.9170, D(G(z)): 0.0612 / 0.0362\n",
      "Epoch [224/500] Batch 0/8 Loss D: 0.7968, Loss G: 7.1780, D(x): 0.9932, D(G(z)): 0.4692 / 0.0029\n",
      "Epoch [225/500] Batch 0/8 Loss D: 0.3876, Loss G: 5.1147, D(x): 0.9684, D(G(z)): 0.2552 / 0.0141\n",
      "Epoch [226/500] Batch 0/8 Loss D: 0.7700, Loss G: 6.7816, D(x): 0.9932, D(G(z)): 0.4421 / 0.0031\n",
      "Epoch [227/500] Batch 0/8 Loss D: 0.2236, Loss G: 4.2374, D(x): 0.9475, D(G(z)): 0.1342 / 0.0259\n",
      "Epoch [228/500] Batch 0/8 Loss D: 0.2906, Loss G: 4.7885, D(x): 0.9730, D(G(z)): 0.2049 / 0.0143\n",
      "Epoch [229/500] Batch 0/8 Loss D: 0.2524, Loss G: 4.7476, D(x): 0.9712, D(G(z)): 0.1764 / 0.0161\n",
      "Epoch [230/500] Batch 0/8 Loss D: 0.1470, Loss G: 3.7965, D(x): 0.9076, D(G(z)): 0.0431 / 0.0388\n",
      "Epoch [231/500] Batch 0/8 Loss D: 0.1514, Loss G: 3.9403, D(x): 0.9532, D(G(z)): 0.0893 / 0.0370\n",
      "Epoch [232/500] Batch 0/8 Loss D: 0.1522, Loss G: 4.3412, D(x): 0.9715, D(G(z)): 0.1085 / 0.0266\n",
      "Epoch [233/500] Batch 0/8 Loss D: 0.5457, Loss G: 6.8309, D(x): 0.9930, D(G(z)): 0.3686 / 0.0021\n",
      "Epoch [234/500] Batch 0/8 Loss D: 0.4326, Loss G: 5.9101, D(x): 0.9788, D(G(z)): 0.2880 / 0.0049\n",
      "Epoch [235/500] Batch 0/8 Loss D: 0.8660, Loss G: 7.6440, D(x): 0.9932, D(G(z)): 0.4604 / 0.0023\n",
      "Epoch [236/500] Batch 0/8 Loss D: 0.4814, Loss G: 6.0361, D(x): 0.9842, D(G(z)): 0.3215 / 0.0058\n",
      "Epoch [237/500] Batch 0/8 Loss D: 0.4554, Loss G: 6.0489, D(x): 0.9845, D(G(z)): 0.3115 / 0.0048\n",
      "Epoch [238/500] Batch 0/8 Loss D: 0.1262, Loss G: 3.9449, D(x): 0.9551, D(G(z)): 0.0720 / 0.0363\n",
      "Epoch [239/500] Batch 0/8 Loss D: 0.7470, Loss G: 7.5277, D(x): 0.9962, D(G(z)): 0.4298 / 0.0020\n",
      "Epoch [240/500] Batch 0/8 Loss D: 0.2311, Loss G: 4.6201, D(x): 0.9534, D(G(z)): 0.1515 / 0.0218\n",
      "Epoch [241/500] Batch 0/8 Loss D: 0.2078, Loss G: 4.8350, D(x): 0.9598, D(G(z)): 0.1341 / 0.0223\n",
      "Epoch [242/500] Batch 0/8 Loss D: 0.1090, Loss G: 4.1549, D(x): 0.9396, D(G(z)): 0.0423 / 0.0299\n",
      "Epoch [243/500] Batch 0/8 Loss D: 0.1668, Loss G: 4.2651, D(x): 0.9715, D(G(z)): 0.1201 / 0.0226\n",
      "Epoch [244/500] Batch 0/8 Loss D: 0.8491, Loss G: 8.1382, D(x): 0.9975, D(G(z)): 0.4794 / 0.0007\n",
      "Epoch [245/500] Batch 0/8 Loss D: 0.2698, Loss G: 4.8287, D(x): 0.9868, D(G(z)): 0.1967 / 0.0135\n",
      "Epoch [246/500] Batch 0/8 Loss D: 1.4236, Loss G: 8.8868, D(x): 0.9957, D(G(z)): 0.5933 / 0.0006\n",
      "Epoch [247/500] Batch 0/8 Loss D: 0.3744, Loss G: 5.7385, D(x): 0.9625, D(G(z)): 0.2174 / 0.0114\n",
      "Epoch [248/500] Batch 0/8 Loss D: 0.1730, Loss G: 3.9175, D(x): 0.9019, D(G(z)): 0.0596 / 0.0369\n",
      "Epoch [249/500] Batch 0/8 Loss D: 0.1623, Loss G: 4.2751, D(x): 0.9582, D(G(z)): 0.1036 / 0.0270\n",
      "Epoch [250/500] Batch 0/8 Loss D: 0.2467, Loss G: 4.8854, D(x): 0.9809, D(G(z)): 0.1826 / 0.0146\n",
      "Epoch [251/500] Batch 0/8 Loss D: 0.1205, Loss G: 4.1513, D(x): 0.9399, D(G(z)): 0.0533 / 0.0276\n",
      "Epoch [252/500] Batch 0/8 Loss D: 0.1220, Loss G: 4.2400, D(x): 0.9209, D(G(z)): 0.0341 / 0.0282\n",
      "Epoch [253/500] Batch 0/8 Loss D: 0.1046, Loss G: 4.3488, D(x): 0.9632, D(G(z)): 0.0608 / 0.0226\n",
      "Epoch [254/500] Batch 0/8 Loss D: 0.1535, Loss G: 4.1818, D(x): 0.9670, D(G(z)): 0.1048 / 0.0265\n",
      "Epoch [255/500] Batch 0/8 Loss D: 0.1229, Loss G: 4.2132, D(x): 0.9099, D(G(z)): 0.0242 / 0.0311\n",
      "Epoch [256/500] Batch 0/8 Loss D: 0.1143, Loss G: 4.5880, D(x): 0.9754, D(G(z)): 0.0786 / 0.0167\n",
      "Epoch [257/500] Batch 0/8 Loss D: 0.1657, Loss G: 4.7420, D(x): 0.9843, D(G(z)): 0.1215 / 0.0155\n",
      "Epoch [258/500] Batch 0/8 Loss D: 0.3661, Loss G: 6.9556, D(x): 0.9931, D(G(z)): 0.2618 / 0.0020\n",
      "Epoch [259/500] Batch 0/8 Loss D: 0.1225, Loss G: 4.3849, D(x): 0.9736, D(G(z)): 0.0868 / 0.0219\n",
      "Epoch [260/500] Batch 0/8 Loss D: 0.1071, Loss G: 4.5502, D(x): 0.9680, D(G(z)): 0.0684 / 0.0163\n",
      "Epoch [261/500] Batch 0/8 Loss D: 0.4313, Loss G: 6.9478, D(x): 0.9959, D(G(z)): 0.3018 / 0.0020\n",
      "Epoch [262/500] Batch 0/8 Loss D: 0.1547, Loss G: 4.4210, D(x): 0.9656, D(G(z)): 0.1051 / 0.0226\n",
      "Epoch [263/500] Batch 0/8 Loss D: 0.1399, Loss G: 4.9261, D(x): 0.9881, D(G(z)): 0.1114 / 0.0126\n",
      "Epoch [264/500] Batch 0/8 Loss D: 0.2722, Loss G: 5.9305, D(x): 0.9880, D(G(z)): 0.2048 / 0.0040\n",
      "Epoch [265/500] Batch 0/8 Loss D: 0.1017, Loss G: 4.4643, D(x): 0.9733, D(G(z)): 0.0686 / 0.0234\n",
      "Epoch [266/500] Batch 0/8 Loss D: 0.4900, Loss G: 7.6143, D(x): 0.9964, D(G(z)): 0.3279 / 0.0010\n",
      "Epoch [267/500] Batch 0/8 Loss D: 0.1341, Loss G: 4.1031, D(x): 0.8926, D(G(z)): 0.0132 / 0.0394\n",
      "Epoch [268/500] Batch 0/8 Loss D: 0.3374, Loss G: 6.8430, D(x): 0.9908, D(G(z)): 0.2441 / 0.0020\n",
      "Epoch [269/500] Batch 0/8 Loss D: 0.1536, Loss G: 4.7757, D(x): 0.8831, D(G(z)): 0.0112 / 0.0219\n",
      "Epoch [270/500] Batch 0/8 Loss D: 1.0923, Loss G: 11.4793, D(x): 0.9964, D(G(z)): 0.5656 / 0.0000\n",
      "Epoch [271/500] Batch 0/8 Loss D: 2.1266, Loss G: 1.7825, D(x): 0.2885, D(G(z)): 0.0231 / 0.3806\n",
      "Epoch [272/500] Batch 0/8 Loss D: 0.3130, Loss G: 4.3262, D(x): 0.8395, D(G(z)): 0.0679 / 0.0582\n",
      "Epoch [273/500] Batch 0/8 Loss D: 0.2122, Loss G: 4.5536, D(x): 0.8805, D(G(z)): 0.0577 / 0.0377\n",
      "Epoch [274/500] Batch 0/8 Loss D: 0.6795, Loss G: 3.7896, D(x): 0.5907, D(G(z)): 0.0077 / 0.0634\n",
      "Epoch [275/500] Batch 0/8 Loss D: 0.1575, Loss G: 3.7676, D(x): 0.9187, D(G(z)): 0.0617 / 0.0441\n",
      "Epoch [276/500] Batch 0/8 Loss D: 0.1605, Loss G: 4.4291, D(x): 0.9532, D(G(z)): 0.0962 / 0.0300\n",
      "Epoch [277/500] Batch 0/8 Loss D: 0.4724, Loss G: 6.1405, D(x): 0.9847, D(G(z)): 0.3149 / 0.0058\n",
      "Epoch [278/500] Batch 0/8 Loss D: 0.1563, Loss G: 4.4561, D(x): 0.8870, D(G(z)): 0.0264 / 0.0290\n",
      "Epoch [279/500] Batch 0/8 Loss D: 0.1254, Loss G: 4.2661, D(x): 0.9586, D(G(z)): 0.0760 / 0.0246\n",
      "Epoch [280/500] Batch 0/8 Loss D: 0.1010, Loss G: 4.3524, D(x): 0.9739, D(G(z)): 0.0681 / 0.0248\n",
      "Epoch [281/500] Batch 0/8 Loss D: 0.3266, Loss G: 5.8081, D(x): 0.9863, D(G(z)): 0.2383 / 0.0056\n",
      "Epoch [282/500] Batch 0/8 Loss D: 0.1448, Loss G: 4.7766, D(x): 0.8809, D(G(z)): 0.0096 / 0.0188\n",
      "Epoch [283/500] Batch 0/8 Loss D: 0.1782, Loss G: 4.7076, D(x): 0.9682, D(G(z)): 0.1139 / 0.0158\n",
      "Epoch [284/500] Batch 0/8 Loss D: 0.1262, Loss G: 4.6415, D(x): 0.9849, D(G(z)): 0.0957 / 0.0173\n",
      "Epoch [285/500] Batch 0/8 Loss D: 0.5842, Loss G: 7.4087, D(x): 0.9962, D(G(z)): 0.3808 / 0.0015\n",
      "Epoch [286/500] Batch 0/8 Loss D: 0.0952, Loss G: 4.4699, D(x): 0.9627, D(G(z)): 0.0518 / 0.0247\n",
      "Epoch [287/500] Batch 0/8 Loss D: 0.0887, Loss G: 3.8254, D(x): 0.9615, D(G(z)): 0.0451 / 0.0352\n",
      "Epoch [288/500] Batch 0/8 Loss D: 0.0840, Loss G: 4.5513, D(x): 0.9592, D(G(z)): 0.0389 / 0.0215\n",
      "Epoch [289/500] Batch 0/8 Loss D: 0.0763, Loss G: 4.1275, D(x): 0.9715, D(G(z)): 0.0443 / 0.0276\n",
      "Epoch [290/500] Batch 0/8 Loss D: 0.1258, Loss G: 4.7464, D(x): 0.9905, D(G(z)): 0.1029 / 0.0145\n",
      "Epoch [291/500] Batch 0/8 Loss D: 0.1477, Loss G: 4.8209, D(x): 0.9897, D(G(z)): 0.1141 / 0.0125\n",
      "Epoch [292/500] Batch 0/8 Loss D: 0.0933, Loss G: 4.4363, D(x): 0.9558, D(G(z)): 0.0436 / 0.0282\n",
      "Epoch [293/500] Batch 0/8 Loss D: 0.1660, Loss G: 5.0335, D(x): 0.9856, D(G(z)): 0.1286 / 0.0128\n",
      "Epoch [294/500] Batch 0/8 Loss D: 0.1028, Loss G: 4.9795, D(x): 0.9806, D(G(z)): 0.0749 / 0.0144\n",
      "Epoch [295/500] Batch 0/8 Loss D: 0.1176, Loss G: 5.0157, D(x): 0.9845, D(G(z)): 0.0869 / 0.0141\n",
      "Epoch [296/500] Batch 0/8 Loss D: 0.2673, Loss G: 6.4034, D(x): 0.9940, D(G(z)): 0.2075 / 0.0029\n",
      "Epoch [297/500] Batch 0/8 Loss D: 0.2045, Loss G: 5.3290, D(x): 0.9948, D(G(z)): 0.1599 / 0.0084\n",
      "Epoch [298/500] Batch 0/8 Loss D: 0.1163, Loss G: 4.9492, D(x): 0.9749, D(G(z)): 0.0804 / 0.0156\n",
      "Epoch [299/500] Batch 0/8 Loss D: 0.0754, Loss G: 4.4232, D(x): 0.9645, D(G(z)): 0.0371 / 0.0205\n",
      "Epoch [300/500] Batch 0/8 Loss D: 0.1123, Loss G: 4.8518, D(x): 0.9905, D(G(z)): 0.0898 / 0.0159\n",
      "Epoch [301/500] Batch 0/8 Loss D: 0.1740, Loss G: 5.3911, D(x): 0.9912, D(G(z)): 0.1415 / 0.0084\n",
      "Epoch [302/500] Batch 0/8 Loss D: 0.1074, Loss G: 5.2609, D(x): 0.9839, D(G(z)): 0.0816 / 0.0131\n",
      "Epoch [303/500] Batch 0/8 Loss D: 0.0651, Loss G: 4.5444, D(x): 0.9632, D(G(z)): 0.0257 / 0.0208\n",
      "Epoch [304/500] Batch 0/8 Loss D: 0.2286, Loss G: 6.7878, D(x): 0.9953, D(G(z)): 0.1771 / 0.0019\n",
      "Epoch [305/500] Batch 0/8 Loss D: 0.0541, Loss G: 4.4279, D(x): 0.9744, D(G(z)): 0.0267 / 0.0209\n",
      "Epoch [306/500] Batch 0/8 Loss D: 0.1358, Loss G: 5.0845, D(x): 0.9909, D(G(z)): 0.1051 / 0.0117\n",
      "Epoch [307/500] Batch 0/8 Loss D: 0.2786, Loss G: 7.9535, D(x): 0.9965, D(G(z)): 0.2148 / 0.0006\n",
      "Epoch [308/500] Batch 0/8 Loss D: 0.1682, Loss G: 5.6862, D(x): 0.9940, D(G(z)): 0.1378 / 0.0058\n",
      "Epoch [309/500] Batch 0/8 Loss D: 0.0583, Loss G: 4.5220, D(x): 0.9805, D(G(z)): 0.0368 / 0.0192\n",
      "Epoch [310/500] Batch 0/8 Loss D: 0.1349, Loss G: 5.5023, D(x): 0.9894, D(G(z)): 0.1098 / 0.0065\n",
      "Epoch [311/500] Batch 0/8 Loss D: 0.0542, Loss G: 4.8363, D(x): 0.9901, D(G(z)): 0.0419 / 0.0168\n",
      "Epoch [312/500] Batch 0/8 Loss D: 0.0988, Loss G: 4.9250, D(x): 0.9943, D(G(z)): 0.0851 / 0.0114\n",
      "Epoch [313/500] Batch 0/8 Loss D: 0.1393, Loss G: 5.5446, D(x): 0.9953, D(G(z)): 0.1182 / 0.0072\n",
      "Epoch [314/500] Batch 0/8 Loss D: 0.0576, Loss G: 4.3354, D(x): 0.9644, D(G(z)): 0.0203 / 0.0207\n",
      "Epoch [315/500] Batch 0/8 Loss D: 0.0673, Loss G: 4.5778, D(x): 0.9854, D(G(z)): 0.0494 / 0.0174\n",
      "Epoch [316/500] Batch 0/8 Loss D: 0.3101, Loss G: 8.3545, D(x): 0.9969, D(G(z)): 0.2321 / 0.0004\n",
      "Epoch [317/500] Batch 0/8 Loss D: 0.3639, Loss G: 8.6343, D(x): 0.9961, D(G(z)): 0.2522 / 0.0004\n",
      "Epoch [318/500] Batch 0/8 Loss D: 0.0803, Loss G: 4.9481, D(x): 0.9736, D(G(z)): 0.0477 / 0.0126\n",
      "Epoch [319/500] Batch 0/8 Loss D: 0.4133, Loss G: 8.0555, D(x): 0.9942, D(G(z)): 0.2719 / 0.0008\n",
      "Epoch [320/500] Batch 0/8 Loss D: 0.0712, Loss G: 4.5266, D(x): 0.9828, D(G(z)): 0.0508 / 0.0177\n",
      "Epoch [321/500] Batch 0/8 Loss D: 0.0629, Loss G: 4.6800, D(x): 0.9808, D(G(z)): 0.0403 / 0.0185\n",
      "Epoch [322/500] Batch 0/8 Loss D: 0.0845, Loss G: 4.8562, D(x): 0.9289, D(G(z)): 0.0077 / 0.0213\n",
      "Epoch [323/500] Batch 0/8 Loss D: 0.0894, Loss G: 4.7776, D(x): 0.9913, D(G(z)): 0.0728 / 0.0160\n",
      "Epoch [324/500] Batch 0/8 Loss D: 0.9184, Loss G: 14.3811, D(x): 0.9988, D(G(z)): 0.5019 / 0.0000\n",
      "Epoch [325/500] Batch 0/8 Loss D: 0.9552, Loss G: 1.8873, D(x): 0.6691, D(G(z)): 0.1145 / 0.3295\n",
      "Epoch [326/500] Batch 0/8 Loss D: 2.3139, Loss G: 11.2633, D(x): 0.9809, D(G(z)): 0.7058 / 0.0005\n",
      "Epoch [327/500] Batch 0/8 Loss D: 0.9942, Loss G: 8.8937, D(x): 0.9511, D(G(z)): 0.4051 / 0.0019\n",
      "Epoch [328/500] Batch 0/8 Loss D: 0.3637, Loss G: 4.5466, D(x): 0.7748, D(G(z)): 0.0440 / 0.0521\n",
      "Epoch [329/500] Batch 0/8 Loss D: 0.1728, Loss G: 4.8281, D(x): 0.9251, D(G(z)): 0.0790 / 0.0160\n",
      "Epoch [330/500] Batch 0/8 Loss D: 0.1581, Loss G: 4.9344, D(x): 0.9433, D(G(z)): 0.0829 / 0.0148\n",
      "Epoch [331/500] Batch 0/8 Loss D: 0.1481, Loss G: 5.0024, D(x): 0.8933, D(G(z)): 0.0229 / 0.0218\n",
      "Epoch [332/500] Batch 0/8 Loss D: 0.1245, Loss G: 4.5878, D(x): 0.9643, D(G(z)): 0.0770 / 0.0197\n",
      "Epoch [333/500] Batch 0/8 Loss D: 0.1105, Loss G: 4.7494, D(x): 0.9382, D(G(z)): 0.0391 / 0.0213\n",
      "Epoch [334/500] Batch 0/8 Loss D: 0.3153, Loss G: 6.3130, D(x): 0.9930, D(G(z)): 0.2303 / 0.0034\n",
      "Epoch [335/500] Batch 0/8 Loss D: 0.0721, Loss G: 4.6748, D(x): 0.9655, D(G(z)): 0.0346 / 0.0173\n",
      "Epoch [336/500] Batch 0/8 Loss D: 0.1794, Loss G: 5.2406, D(x): 0.9881, D(G(z)): 0.1321 / 0.0111\n",
      "Epoch [337/500] Batch 0/8 Loss D: 0.5015, Loss G: 7.6088, D(x): 0.9967, D(G(z)): 0.3371 / 0.0010\n",
      "Epoch [338/500] Batch 0/8 Loss D: 0.1078, Loss G: 4.5559, D(x): 0.9658, D(G(z)): 0.0657 / 0.0191\n",
      "Epoch [339/500] Batch 0/8 Loss D: 0.0789, Loss G: 4.3742, D(x): 0.9689, D(G(z)): 0.0440 / 0.0222\n",
      "Epoch [340/500] Batch 0/8 Loss D: 0.0808, Loss G: 4.2898, D(x): 0.9637, D(G(z)): 0.0407 / 0.0223\n",
      "Epoch [341/500] Batch 0/8 Loss D: 0.0564, Loss G: 4.9452, D(x): 0.9640, D(G(z)): 0.0185 / 0.0144\n",
      "Epoch [342/500] Batch 0/8 Loss D: 0.0679, Loss G: 4.5512, D(x): 0.9744, D(G(z)): 0.0397 / 0.0218\n",
      "Epoch [343/500] Batch 0/8 Loss D: 0.0368, Loss G: 5.0606, D(x): 0.9812, D(G(z)): 0.0172 / 0.0111\n",
      "Epoch [344/500] Batch 0/8 Loss D: 0.7729, Loss G: 12.7362, D(x): 0.9982, D(G(z)): 0.4655 / 0.0000\n",
      "Epoch [345/500] Batch 0/8 Loss D: 0.1602, Loss G: 4.4224, D(x): 0.9195, D(G(z)): 0.0613 / 0.0330\n",
      "Epoch [346/500] Batch 0/8 Loss D: 0.0906, Loss G: 5.3398, D(x): 0.9794, D(G(z)): 0.0583 / 0.0109\n",
      "Epoch [347/500] Batch 0/8 Loss D: 0.0795, Loss G: 4.8774, D(x): 0.9720, D(G(z)): 0.0463 / 0.0153\n",
      "Epoch [348/500] Batch 0/8 Loss D: 0.0700, Loss G: 4.6947, D(x): 0.9807, D(G(z)): 0.0464 / 0.0183\n",
      "Epoch [349/500] Batch 0/8 Loss D: 0.0789, Loss G: 4.6380, D(x): 0.9838, D(G(z)): 0.0582 / 0.0173\n",
      "Epoch [350/500] Batch 0/8 Loss D: 0.0734, Loss G: 5.0404, D(x): 0.9825, D(G(z)): 0.0488 / 0.0133\n",
      "Epoch [351/500] Batch 0/8 Loss D: 0.0726, Loss G: 4.6892, D(x): 0.9819, D(G(z)): 0.0510 / 0.0150\n",
      "Epoch [352/500] Batch 0/8 Loss D: 0.0843, Loss G: 4.8191, D(x): 0.9909, D(G(z)): 0.0687 / 0.0152\n",
      "Epoch [353/500] Batch 0/8 Loss D: 0.0826, Loss G: 4.9714, D(x): 0.9904, D(G(z)): 0.0649 / 0.0129\n",
      "Epoch [354/500] Batch 0/8 Loss D: 0.0492, Loss G: 4.6868, D(x): 0.9854, D(G(z)): 0.0328 / 0.0170\n",
      "Epoch [355/500] Batch 0/8 Loss D: 0.0412, Loss G: 4.9589, D(x): 0.9819, D(G(z)): 0.0223 / 0.0129\n",
      "Epoch [356/500] Batch 0/8 Loss D: 0.0615, Loss G: 4.7026, D(x): 0.9523, D(G(z)): 0.0114 / 0.0171\n",
      "Epoch [357/500] Batch 0/8 Loss D: 0.0649, Loss G: 5.2533, D(x): 0.9902, D(G(z)): 0.0505 / 0.0107\n",
      "Epoch [358/500] Batch 0/8 Loss D: 0.0409, Loss G: 4.5854, D(x): 0.9861, D(G(z)): 0.0260 / 0.0175\n",
      "Epoch [359/500] Batch 0/8 Loss D: 0.0414, Loss G: 4.6928, D(x): 0.9809, D(G(z)): 0.0215 / 0.0154\n",
      "Epoch [360/500] Batch 0/8 Loss D: 0.2358, Loss G: 7.7283, D(x): 0.9973, D(G(z)): 0.1865 / 0.0007\n",
      "Epoch [361/500] Batch 0/8 Loss D: 0.1070, Loss G: 4.9960, D(x): 0.9966, D(G(z)): 0.0931 / 0.0128\n",
      "Epoch [362/500] Batch 0/8 Loss D: 0.0491, Loss G: 4.6145, D(x): 0.9896, D(G(z)): 0.0361 / 0.0196\n",
      "Epoch [363/500] Batch 0/8 Loss D: 0.0452, Loss G: 4.6999, D(x): 0.9809, D(G(z)): 0.0247 / 0.0157\n",
      "Epoch [364/500] Batch 0/8 Loss D: 0.5585, Loss G: 10.9589, D(x): 0.9992, D(G(z)): 0.3561 / 0.0001\n",
      "Epoch [365/500] Batch 0/8 Loss D: 0.0650, Loss G: 5.3752, D(x): 0.9779, D(G(z)): 0.0390 / 0.0111\n",
      "Epoch [366/500] Batch 0/8 Loss D: 0.0679, Loss G: 4.9583, D(x): 0.9854, D(G(z)): 0.0495 / 0.0134\n",
      "Epoch [367/500] Batch 0/8 Loss D: 0.0402, Loss G: 5.2417, D(x): 0.9701, D(G(z)): 0.0091 / 0.0101\n",
      "Epoch [368/500] Batch 0/8 Loss D: 0.0337, Loss G: 5.2886, D(x): 0.9793, D(G(z)): 0.0124 / 0.0093\n",
      "Epoch [369/500] Batch 0/8 Loss D: 0.0717, Loss G: 4.7507, D(x): 0.9943, D(G(z)): 0.0616 / 0.0136\n",
      "Epoch [370/500] Batch 0/8 Loss D: 0.0743, Loss G: 4.7161, D(x): 0.9951, D(G(z)): 0.0646 / 0.0169\n",
      "Epoch [371/500] Batch 0/8 Loss D: 0.1763, Loss G: 6.4921, D(x): 0.9971, D(G(z)): 0.1440 / 0.0026\n",
      "Epoch [372/500] Batch 0/8 Loss D: 0.6412, Loss G: 11.7479, D(x): 0.9990, D(G(z)): 0.3963 / 0.0000\n",
      "Epoch [373/500] Batch 0/8 Loss D: 0.0867, Loss G: 5.9407, D(x): 0.9819, D(G(z)): 0.0625 / 0.0049\n",
      "Epoch [374/500] Batch 0/8 Loss D: 0.0684, Loss G: 4.8162, D(x): 0.9703, D(G(z)): 0.0348 / 0.0163\n",
      "Epoch [375/500] Batch 0/8 Loss D: 0.0456, Loss G: 5.2366, D(x): 0.9784, D(G(z)): 0.0228 / 0.0104\n",
      "Epoch [376/500] Batch 0/8 Loss D: 0.1144, Loss G: 5.6500, D(x): 0.9944, D(G(z)): 0.0945 / 0.0061\n",
      "Epoch [377/500] Batch 0/8 Loss D: 0.0423, Loss G: 5.2751, D(x): 0.9707, D(G(z)): 0.0118 / 0.0101\n",
      "Epoch [378/500] Batch 0/8 Loss D: 0.0431, Loss G: 4.8973, D(x): 0.9855, D(G(z)): 0.0272 / 0.0135\n",
      "Epoch [379/500] Batch 0/8 Loss D: 0.0460, Loss G: 4.5510, D(x): 0.9795, D(G(z)): 0.0242 / 0.0188\n",
      "Epoch [380/500] Batch 0/8 Loss D: 0.0362, Loss G: 4.8843, D(x): 0.9911, D(G(z)): 0.0261 / 0.0133\n",
      "Epoch [381/500] Batch 0/8 Loss D: 0.1951, Loss G: 6.9432, D(x): 0.9966, D(G(z)): 0.1540 / 0.0020\n",
      "Epoch [382/500] Batch 0/8 Loss D: 0.0887, Loss G: 4.9806, D(x): 0.9965, D(G(z)): 0.0771 / 0.0135\n",
      "Epoch [383/500] Batch 0/8 Loss D: 0.0369, Loss G: 5.5225, D(x): 0.9762, D(G(z)): 0.0122 / 0.0094\n",
      "Epoch [384/500] Batch 0/8 Loss D: 0.0427, Loss G: 5.1712, D(x): 0.9919, D(G(z)): 0.0325 / 0.0108\n",
      "Epoch [385/500] Batch 0/8 Loss D: 0.0586, Loss G: 5.0418, D(x): 0.9916, D(G(z)): 0.0474 / 0.0120\n",
      "Epoch [386/500] Batch 0/8 Loss D: 0.4659, Loss G: 12.2018, D(x): 0.9988, D(G(z)): 0.3293 / 0.0000\n",
      "Epoch [387/500] Batch 0/8 Loss D: 0.8816, Loss G: 4.5135, D(x): 0.6224, D(G(z)): 0.0338 / 0.1279\n",
      "Epoch [388/500] Batch 0/8 Loss D: 0.5224, Loss G: 7.6657, D(x): 0.8537, D(G(z)): 0.1163 / 0.0046\n",
      "Epoch [389/500] Batch 0/8 Loss D: 0.2128, Loss G: 5.0069, D(x): 0.8728, D(G(z)): 0.0428 / 0.0333\n",
      "Epoch [390/500] Batch 0/8 Loss D: 0.1021, Loss G: 5.1553, D(x): 0.9683, D(G(z)): 0.0618 / 0.0166\n",
      "Epoch [391/500] Batch 0/8 Loss D: 0.1185, Loss G: 5.8517, D(x): 0.9109, D(G(z)): 0.0150 / 0.0100\n",
      "Epoch [392/500] Batch 0/8 Loss D: 0.1063, Loss G: 5.4541, D(x): 0.9389, D(G(z)): 0.0357 / 0.0122\n",
      "Epoch [393/500] Batch 0/8 Loss D: 0.0760, Loss G: 5.0156, D(x): 0.9767, D(G(z)): 0.0479 / 0.0162\n",
      "Epoch [394/500] Batch 0/8 Loss D: 0.0714, Loss G: 5.0436, D(x): 0.9689, D(G(z)): 0.0374 / 0.0145\n",
      "Epoch [395/500] Batch 0/8 Loss D: 0.1197, Loss G: 5.8659, D(x): 0.9917, D(G(z)): 0.0979 / 0.0058\n",
      "Epoch [396/500] Batch 0/8 Loss D: 0.0638, Loss G: 4.5966, D(x): 0.9767, D(G(z)): 0.0380 / 0.0178\n",
      "Epoch [397/500] Batch 0/8 Loss D: 0.0714, Loss G: 5.4188, D(x): 0.9879, D(G(z)): 0.0542 / 0.0102\n",
      "Epoch [398/500] Batch 0/8 Loss D: 0.2426, Loss G: 7.8187, D(x): 0.9969, D(G(z)): 0.1904 / 0.0009\n",
      "Epoch [399/500] Batch 0/8 Loss D: 0.5986, Loss G: 11.8548, D(x): 0.9986, D(G(z)): 0.3775 / 0.0000\n",
      "Epoch [400/500] Batch 0/8 Loss D: 0.2777, Loss G: 7.3373, D(x): 0.9935, D(G(z)): 0.2011 / 0.0017\n",
      "Epoch [401/500] Batch 0/8 Loss D: 1.2604, Loss G: 14.1014, D(x): 0.9995, D(G(z)): 0.5687 / 0.0000\n",
      "Epoch [402/500] Batch 0/8 Loss D: 0.1343, Loss G: 6.5193, D(x): 0.9848, D(G(z)): 0.0941 / 0.0085\n",
      "Epoch [403/500] Batch 0/8 Loss D: 0.0659, Loss G: 5.0299, D(x): 0.9667, D(G(z)): 0.0295 / 0.0171\n",
      "Epoch [404/500] Batch 0/8 Loss D: 0.0588, Loss G: 5.3488, D(x): 0.9741, D(G(z)): 0.0303 / 0.0127\n",
      "Epoch [405/500] Batch 0/8 Loss D: 0.1672, Loss G: 6.3769, D(x): 0.9889, D(G(z)): 0.1240 / 0.0056\n",
      "Epoch [406/500] Batch 0/8 Loss D: 0.0570, Loss G: 5.6719, D(x): 0.9602, D(G(z)): 0.0147 / 0.0087\n",
      "Epoch [407/500] Batch 0/8 Loss D: 0.0409, Loss G: 5.3289, D(x): 0.9831, D(G(z)): 0.0230 / 0.0123\n",
      "Epoch [408/500] Batch 0/8 Loss D: 0.0413, Loss G: 5.4777, D(x): 0.9776, D(G(z)): 0.0176 / 0.0094\n",
      "Epoch [409/500] Batch 0/8 Loss D: 0.0495, Loss G: 5.2042, D(x): 0.9888, D(G(z)): 0.0358 / 0.0098\n",
      "Epoch [410/500] Batch 0/8 Loss D: 0.0829, Loss G: 5.4611, D(x): 0.9948, D(G(z)): 0.0711 / 0.0083\n",
      "Epoch [411/500] Batch 0/8 Loss D: 0.0463, Loss G: 4.8329, D(x): 0.9949, D(G(z)): 0.0395 / 0.0157\n",
      "Epoch [412/500] Batch 0/8 Loss D: 0.0595, Loss G: 5.2237, D(x): 0.9921, D(G(z)): 0.0452 / 0.0109\n",
      "Epoch [413/500] Batch 0/8 Loss D: 0.0672, Loss G: 5.2087, D(x): 0.9927, D(G(z)): 0.0536 / 0.0104\n",
      "Epoch [414/500] Batch 0/8 Loss D: 0.0299, Loss G: 5.3831, D(x): 0.9885, D(G(z)): 0.0178 / 0.0100\n",
      "Epoch [415/500] Batch 0/8 Loss D: 0.0326, Loss G: 5.1117, D(x): 0.9883, D(G(z)): 0.0202 / 0.0121\n",
      "Epoch [416/500] Batch 0/8 Loss D: 0.0315, Loss G: 5.3361, D(x): 0.9822, D(G(z)): 0.0131 / 0.0097\n",
      "Epoch [417/500] Batch 0/8 Loss D: 0.0989, Loss G: 6.0593, D(x): 0.9965, D(G(z)): 0.0834 / 0.0059\n",
      "Epoch [418/500] Batch 0/8 Loss D: 0.0196, Loss G: 5.8327, D(x): 0.9887, D(G(z)): 0.0080 / 0.0065\n",
      "Epoch [419/500] Batch 0/8 Loss D: 0.0583, Loss G: 5.4652, D(x): 0.9946, D(G(z)): 0.0475 / 0.0112\n",
      "Epoch [420/500] Batch 0/8 Loss D: 0.0360, Loss G: 5.1031, D(x): 0.9919, D(G(z)): 0.0269 / 0.0111\n",
      "Epoch [421/500] Batch 0/8 Loss D: 0.1277, Loss G: 6.3864, D(x): 0.9984, D(G(z)): 0.1075 / 0.0040\n",
      "Epoch [422/500] Batch 0/8 Loss D: 0.1162, Loss G: 5.8922, D(x): 0.9956, D(G(z)): 0.0952 / 0.0059\n",
      "Epoch [423/500] Batch 0/8 Loss D: 0.0443, Loss G: 5.2658, D(x): 0.9868, D(G(z)): 0.0287 / 0.0139\n",
      "Epoch [424/500] Batch 0/8 Loss D: 0.0432, Loss G: 5.1473, D(x): 0.9929, D(G(z)): 0.0345 / 0.0119\n",
      "Epoch [425/500] Batch 0/8 Loss D: 0.1493, Loss G: 7.7126, D(x): 0.9986, D(G(z)): 0.1230 / 0.0013\n",
      "Epoch [426/500] Batch 0/8 Loss D: 0.0352, Loss G: 5.3501, D(x): 0.9942, D(G(z)): 0.0275 / 0.0130\n",
      "Epoch [427/500] Batch 0/8 Loss D: 0.0265, Loss G: 5.3832, D(x): 0.9836, D(G(z)): 0.0097 / 0.0081\n",
      "Epoch [428/500] Batch 0/8 Loss D: 0.0313, Loss G: 5.1310, D(x): 0.9803, D(G(z)): 0.0112 / 0.0103\n",
      "Epoch [429/500] Batch 0/8 Loss D: 0.0307, Loss G: 5.1046, D(x): 0.9958, D(G(z)): 0.0254 / 0.0130\n",
      "Epoch [430/500] Batch 0/8 Loss D: 0.0281, Loss G: 5.0049, D(x): 0.9955, D(G(z)): 0.0229 / 0.0153\n",
      "Epoch [431/500] Batch 0/8 Loss D: 0.3892, Loss G: 11.8442, D(x): 0.9994, D(G(z)): 0.2627 / 0.0000\n",
      "Epoch [432/500] Batch 0/8 Loss D: 0.1222, Loss G: 6.2770, D(x): 0.9927, D(G(z)): 0.0947 / 0.0040\n",
      "Epoch [433/500] Batch 0/8 Loss D: 0.0326, Loss G: 5.3135, D(x): 0.9849, D(G(z)): 0.0168 / 0.0108\n",
      "Epoch [434/500] Batch 0/8 Loss D: 1.2234, Loss G: 21.1592, D(x): 0.9997, D(G(z)): 0.5659 / 0.0000\n",
      "Epoch [435/500] Batch 0/8 Loss D: 0.7275, Loss G: 10.8660, D(x): 0.6851, D(G(z)): 0.0021 / 0.0192\n",
      "Epoch [436/500] Batch 0/8 Loss D: 0.7348, Loss G: 6.7771, D(x): 0.8246, D(G(z)): 0.2208 / 0.0091\n",
      "Epoch [437/500] Batch 0/8 Loss D: 0.5757, Loss G: 9.8050, D(x): 0.9266, D(G(z)): 0.2544 / 0.0005\n",
      "Epoch [438/500] Batch 0/8 Loss D: 0.3303, Loss G: 7.1554, D(x): 0.9765, D(G(z)): 0.1925 / 0.0042\n",
      "Epoch [439/500] Batch 0/8 Loss D: 1.2088, Loss G: 11.4679, D(x): 0.9942, D(G(z)): 0.4886 / 0.0003\n",
      "Epoch [440/500] Batch 0/8 Loss D: 0.2672, Loss G: 7.2093, D(x): 0.9848, D(G(z)): 0.1652 / 0.0062\n",
      "Epoch [441/500] Batch 0/8 Loss D: 0.3185, Loss G: 8.2143, D(x): 0.9787, D(G(z)): 0.2029 / 0.0010\n",
      "Epoch [442/500] Batch 0/8 Loss D: 0.1614, Loss G: 6.1499, D(x): 0.9477, D(G(z)): 0.0755 / 0.0150\n",
      "Epoch [443/500] Batch 0/8 Loss D: 0.1243, Loss G: 5.7768, D(x): 0.9092, D(G(z)): 0.0169 / 0.0111\n",
      "Epoch [444/500] Batch 0/8 Loss D: 0.4487, Loss G: 8.6557, D(x): 0.9707, D(G(z)): 0.2582 / 0.0006\n",
      "Epoch [445/500] Batch 0/8 Loss D: 0.2802, Loss G: 6.8884, D(x): 0.9823, D(G(z)): 0.1854 / 0.0034\n",
      "Epoch [446/500] Batch 0/8 Loss D: 0.0995, Loss G: 5.3067, D(x): 0.9367, D(G(z)): 0.0281 / 0.0150\n",
      "Epoch [447/500] Batch 0/8 Loss D: 0.1004, Loss G: 5.7727, D(x): 0.9888, D(G(z)): 0.0748 / 0.0097\n",
      "Epoch [448/500] Batch 0/8 Loss D: 0.0609, Loss G: 5.6955, D(x): 0.9808, D(G(z)): 0.0378 / 0.0127\n",
      "Epoch [449/500] Batch 0/8 Loss D: 0.0783, Loss G: 5.0689, D(x): 0.9749, D(G(z)): 0.0482 / 0.0132\n",
      "Epoch [450/500] Batch 0/8 Loss D: 0.1711, Loss G: 6.5320, D(x): 0.9923, D(G(z)): 0.1281 / 0.0034\n",
      "Epoch [451/500] Batch 0/8 Loss D: 0.4752, Loss G: 10.1726, D(x): 0.9979, D(G(z)): 0.3146 / 0.0002\n",
      "Epoch [452/500] Batch 0/8 Loss D: 0.1041, Loss G: 5.5567, D(x): 0.9835, D(G(z)): 0.0737 / 0.0105\n",
      "Epoch [453/500] Batch 0/8 Loss D: 0.0738, Loss G: 5.6619, D(x): 0.9850, D(G(z)): 0.0491 / 0.0092\n",
      "Epoch [454/500] Batch 0/8 Loss D: 0.0784, Loss G: 5.5405, D(x): 0.9868, D(G(z)): 0.0588 / 0.0073\n",
      "Epoch [455/500] Batch 0/8 Loss D: 0.0867, Loss G: 5.5838, D(x): 0.9939, D(G(z)): 0.0718 / 0.0080\n",
      "Epoch [456/500] Batch 0/8 Loss D: 0.0750, Loss G: 5.4860, D(x): 0.9860, D(G(z)): 0.0562 / 0.0085\n",
      "Epoch [457/500] Batch 0/8 Loss D: 0.0899, Loss G: 5.4989, D(x): 0.9925, D(G(z)): 0.0756 / 0.0070\n",
      "Epoch [458/500] Batch 0/8 Loss D: 0.0491, Loss G: 5.4323, D(x): 0.9654, D(G(z)): 0.0125 / 0.0116\n",
      "Epoch [459/500] Batch 0/8 Loss D: 0.0418, Loss G: 5.7078, D(x): 0.9843, D(G(z)): 0.0239 / 0.0076\n",
      "Epoch [460/500] Batch 0/8 Loss D: 0.1463, Loss G: 6.9717, D(x): 0.9974, D(G(z)): 0.1211 / 0.0020\n",
      "Epoch [461/500] Batch 0/8 Loss D: 0.0487, Loss G: 5.3047, D(x): 0.9905, D(G(z)): 0.0369 / 0.0102\n",
      "Epoch [462/500] Batch 0/8 Loss D: 0.0392, Loss G: 5.9149, D(x): 0.9897, D(G(z)): 0.0261 / 0.0064\n",
      "Epoch [463/500] Batch 0/8 Loss D: 0.0278, Loss G: 5.6309, D(x): 0.9821, D(G(z)): 0.0094 / 0.0069\n",
      "Epoch [464/500] Batch 0/8 Loss D: 1.5666, Loss G: 20.6710, D(x): 0.9998, D(G(z)): 0.6964 / 0.0000\n",
      "Epoch [465/500] Batch 0/8 Loss D: 2.0368, Loss G: 9.8688, D(x): 0.9989, D(G(z)): 0.6621 / 0.0019\n",
      "Epoch [466/500] Batch 0/8 Loss D: 0.2087, Loss G: 6.7062, D(x): 0.8872, D(G(z)): 0.0445 / 0.0241\n",
      "Epoch [467/500] Batch 0/8 Loss D: 0.5520, Loss G: 8.7800, D(x): 0.9914, D(G(z)): 0.3322 / 0.0006\n",
      "Epoch [468/500] Batch 0/8 Loss D: 0.2803, Loss G: 6.7744, D(x): 0.9789, D(G(z)): 0.1641 / 0.0029\n",
      "Epoch [469/500] Batch 0/8 Loss D: 0.0783, Loss G: 6.0146, D(x): 0.9718, D(G(z)): 0.0434 / 0.0059\n",
      "Epoch [470/500] Batch 0/8 Loss D: 0.7789, Loss G: 14.2269, D(x): 0.9983, D(G(z)): 0.4525 / 0.0000\n",
      "Epoch [471/500] Batch 0/8 Loss D: 0.2897, Loss G: 7.4240, D(x): 0.9919, D(G(z)): 0.1977 / 0.0018\n",
      "Epoch [472/500] Batch 0/8 Loss D: 0.6377, Loss G: 10.6007, D(x): 0.9971, D(G(z)): 0.3621 / 0.0002\n",
      "Epoch [473/500] Batch 0/8 Loss D: 0.0794, Loss G: 5.1446, D(x): 0.9773, D(G(z)): 0.0499 / 0.0148\n",
      "Epoch [474/500] Batch 0/8 Loss D: 0.0956, Loss G: 4.8759, D(x): 0.9739, D(G(z)): 0.0616 / 0.0183\n",
      "Epoch [475/500] Batch 0/8 Loss D: 0.0407, Loss G: 5.6880, D(x): 0.9761, D(G(z)): 0.0156 / 0.0085\n",
      "Epoch [476/500] Batch 0/8 Loss D: 0.0528, Loss G: 5.4023, D(x): 0.9879, D(G(z)): 0.0385 / 0.0105\n",
      "Epoch [477/500] Batch 0/8 Loss D: 0.0349, Loss G: 5.4510, D(x): 0.9874, D(G(z)): 0.0213 / 0.0101\n",
      "Epoch [478/500] Batch 0/8 Loss D: 0.0574, Loss G: 5.5126, D(x): 0.9895, D(G(z)): 0.0437 / 0.0093\n",
      "Epoch [479/500] Batch 0/8 Loss D: 0.2764, Loss G: 9.2669, D(x): 0.9976, D(G(z)): 0.1961 / 0.0005\n",
      "Epoch [480/500] Batch 0/8 Loss D: 0.0388, Loss G: 5.5062, D(x): 0.9864, D(G(z)): 0.0237 / 0.0098\n",
      "Epoch [481/500] Batch 0/8 Loss D: 0.0571, Loss G: 5.5618, D(x): 0.9931, D(G(z)): 0.0470 / 0.0074\n",
      "Epoch [482/500] Batch 0/8 Loss D: 0.0377, Loss G: 5.7320, D(x): 0.9871, D(G(z)): 0.0233 / 0.0087\n",
      "Epoch [483/500] Batch 0/8 Loss D: 0.0359, Loss G: 5.5442, D(x): 0.9921, D(G(z)): 0.0267 / 0.0101\n",
      "Epoch [484/500] Batch 0/8 Loss D: 0.0641, Loss G: 6.2364, D(x): 0.9909, D(G(z)): 0.0499 / 0.0052\n",
      "Epoch [485/500] Batch 0/8 Loss D: 0.0277, Loss G: 5.5401, D(x): 0.9893, D(G(z)): 0.0164 / 0.0068\n",
      "Epoch [486/500] Batch 0/8 Loss D: 0.0407, Loss G: 5.5748, D(x): 0.9886, D(G(z)): 0.0280 / 0.0071\n",
      "Epoch [487/500] Batch 0/8 Loss D: 0.0285, Loss G: 5.7830, D(x): 0.9834, D(G(z)): 0.0114 / 0.0061\n",
      "Epoch [488/500] Batch 0/8 Loss D: 0.1200, Loss G: 7.7486, D(x): 0.9985, D(G(z)): 0.1047 / 0.0010\n",
      "Epoch [489/500] Batch 0/8 Loss D: 0.0383, Loss G: 5.9820, D(x): 0.9941, D(G(z)): 0.0287 / 0.0065\n",
      "Epoch [490/500] Batch 0/8 Loss D: 0.0264, Loss G: 6.1311, D(x): 0.9871, D(G(z)): 0.0130 / 0.0074\n",
      "Epoch [491/500] Batch 0/8 Loss D: 0.0223, Loss G: 5.7326, D(x): 0.9942, D(G(z)): 0.0160 / 0.0071\n",
      "Epoch [492/500] Batch 0/8 Loss D: 0.0169, Loss G: 6.0296, D(x): 0.9913, D(G(z)): 0.0080 / 0.0056\n",
      "Epoch [493/500] Batch 0/8 Loss D: 0.0228, Loss G: 5.6506, D(x): 0.9939, D(G(z)): 0.0164 / 0.0081\n",
      "Epoch [494/500] Batch 0/8 Loss D: 0.0174, Loss G: 5.8696, D(x): 0.9909, D(G(z)): 0.0081 / 0.0051\n",
      "Epoch [495/500] Batch 0/8 Loss D: 0.0222, Loss G: 6.3601, D(x): 0.9930, D(G(z)): 0.0142 / 0.0040\n",
      "Epoch [496/500] Batch 0/8 Loss D: 0.0202, Loss G: 6.5683, D(x): 0.9959, D(G(z)): 0.0157 / 0.0028\n",
      "Epoch [497/500] Batch 0/8 Loss D: 0.0308, Loss G: 7.4975, D(x): 0.9896, D(G(z)): 0.0198 / 0.0012\n",
      "Epoch [498/500] Batch 0/8 Loss D: 0.0249, Loss G: 9.4478, D(x): 0.9929, D(G(z)): 0.0170 / 0.0002\n",
      "Epoch [499/500] Batch 0/8 Loss D: 0.4194, Loss G: 58.3337, D(x): 0.7544, D(G(z)): 0.0000 / 0.0000\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"D:/Uni/GAN_powered_Pokemon_Generation/data/All_Generations\"\n",
    "output_folder = \"D:/Uni/GAN_powered_Pokemon_Generation/lab/output\"\n",
    "train_gan(data_folder, output_folder, num_epochs=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan_pokemon_generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
